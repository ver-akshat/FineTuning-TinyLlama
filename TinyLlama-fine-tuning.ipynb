{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### TinyLLAMA Fine Tuning-","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"#### TinyLlama is a smaller model which has 1.1 Billion parameters & trained on 3 Trillion tokens, it has same architecture and tokenizer as Llama-2","metadata":{}},{"cell_type":"markdown","source":"#### Fine Tuning TinyLlama on a custom dataset for sentiment analysis","metadata":{}},{"cell_type":"code","source":"# Specific versions needs to be installed\n!pip install accelerate==0.26.1 peft==0.7.1 bitsandbytes==0.42.0 transformers==4.35.2 trl==0.7.10 datasets==2.16.1 ","metadata":{"execution":{"iopub.status.busy":"2024-04-06T07:10:56.208007Z","iopub.execute_input":"2024-04-06T07:10:56.208805Z","iopub.status.idle":"2024-04-06T07:11:33.901220Z","shell.execute_reply.started":"2024-04-06T07:10:56.208775Z","shell.execute_reply":"2024-04-06T07:11:33.900232Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting accelerate==0.26.1\n  Downloading accelerate-0.26.1-py3-none-any.whl.metadata (18 kB)\nCollecting peft==0.7.1\n  Downloading peft-0.7.1-py3-none-any.whl.metadata (25 kB)\nCollecting bitsandbytes==0.42.0\n  Downloading bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\nCollecting transformers==4.35.2\n  Downloading transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting trl==0.7.10\n  Downloading trl-0.7.10-py3-none-any.whl.metadata (10 kB)\nCollecting datasets==2.16.1\n  Downloading datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.26.1) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.26.1) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.26.1) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.26.1) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.26.1) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate==0.26.1) (0.21.4)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.26.1) (0.4.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft==0.7.1) (4.66.1)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes==0.42.0) (1.11.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2) (3.13.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2) (0.15.2)\nCollecting tyro>=0.5.11 (from trl==0.7.10)\n  Downloading tyro-0.8.2-py3-none-any.whl.metadata (7.9 kB)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.1) (11.0.0)\nCollecting pyarrow-hotfix (from datasets==2.16.1)\n  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\nCollecting dill<0.3.8,>=0.3.0 (from datasets==2.16.1)\n  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.1) (2.1.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.1) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.1) (0.70.16)\nCollecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.16.1)\n  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.1) (3.9.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.26.1) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate==0.26.1) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2) (2024.2.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (3.1.2)\nRequirement already satisfied: docstring-parser>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.7.10) (0.15)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.7.10) (13.7.0)\nCollecting shtab>=1.5.6 (from tyro>=0.5.11->trl==0.7.10)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nINFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\nCollecting multiprocess (from datasets==2.16.1)\n  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.16.1) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.16.1) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.16.1) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.16.1) (1.16.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.10) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.10) (2.17.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.26.1) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.26.1) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.7.10) (0.1.2)\nDownloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading peft-0.7.1-py3-none-any.whl (168 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading trl-0.7.10-py3-none-any.whl (150 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.9/150.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading datasets-2.16.1-py3-none-any.whl (507 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tyro-0.8.2-py3-none-any.whl (80 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.1/80.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\nDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nInstalling collected packages: shtab, pyarrow-hotfix, fsspec, dill, multiprocess, bitsandbytes, tyro, accelerate, transformers, datasets, trl, peft\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2024.3.0\n    Uninstalling fsspec-2024.3.0:\n      Successfully uninstalled fsspec-2024.3.0\n  Attempting uninstall: dill\n    Found existing installation: dill 0.3.8\n    Uninstalling dill-0.3.8:\n      Successfully uninstalled dill-0.3.8\n  Attempting uninstall: multiprocess\n    Found existing installation: multiprocess 0.70.16\n    Uninstalling multiprocess-0.70.16:\n      Successfully uninstalled multiprocess-0.70.16\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.28.0\n    Uninstalling accelerate-0.28.0:\n      Successfully uninstalled accelerate-0.28.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.38.2\n    Uninstalling transformers-4.38.2:\n      Successfully uninstalled transformers-4.38.2\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ngcsfs 2023.12.2.post1 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\npathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\npathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ns3fs 2024.3.0 requires fsspec==2024.3.0, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-0.26.1 bitsandbytes-0.42.0 datasets-2.16.1 dill-0.3.7 fsspec-2023.10.0 multiprocess-0.70.15 peft-0.7.1 pyarrow-hotfix-0.6 shtab-1.7.1 transformers-4.35.2 trl-0.7.10 tyro-0.8.2\n","output_type":"stream"}]},{"cell_type":"code","source":"# imports \nfrom datasets import load_dataset\nimport torch\nfrom peft import LoraConfig,PeftModel\nfrom trl import SFTTrainer\nimport os\nfrom transformers import AutoModelForCausalLM,AutoTokenizer,BitsAndBytesConfig,TrainingArguments,GenerationConfig","metadata":{"execution":{"iopub.status.busy":"2024-04-06T07:14:34.386582Z","iopub.execute_input":"2024-04-06T07:14:34.386909Z","iopub.status.idle":"2024-04-06T07:14:34.392193Z","shell.execute_reply.started":"2024-04-06T07:14:34.386885Z","shell.execute_reply":"2024-04-06T07:14:34.391319Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"#### Dataset handling-","metadata":{}},{"cell_type":"code","source":"data=load_dataset('dair-ai/emotion','split')\ndata","metadata":{"execution":{"iopub.status.busy":"2024-04-06T07:15:49.426177Z","iopub.execute_input":"2024-04-06T07:15:49.426559Z","iopub.status.idle":"2024-04-06T07:15:54.268228Z","shell.execute_reply.started":"2024-04-06T07:15:49.426525Z","shell.execute_reply":"2024-04-06T07:15:54.267419Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"592a29501c3c45da9d3dcaf99f31663c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/127k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5559cb099d494f409bc16dad7c256bb8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/129k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0acd6032fd9e4c5a9b0f4dfb175f2909"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/16000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4bfcf8e7a5246789a6e6eb944be4fad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57628277fa634023b810f88b06fde9bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f393a327a6344ac78043e58d4439fa66"}},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 16000\n    })\n    validation: Dataset({\n        features: ['text', 'label'],\n        num_rows: 2000\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"data['train'][9]","metadata":{"execution":{"iopub.status.busy":"2024-04-06T07:16:05.752842Z","iopub.execute_input":"2024-04-06T07:16:05.753439Z","iopub.status.idle":"2024-04-06T07:16:05.759649Z","shell.execute_reply.started":"2024-04-06T07:16:05.753405Z","shell.execute_reply":"2024-04-06T07:16:05.758694Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'text': 'i feel romantic too', 'label': 2}"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Need to convert numerical labels to alphabetical","metadata":{"execution":{"iopub.status.busy":"2024-04-06T07:16:49.335056Z","iopub.execute_input":"2024-04-06T07:16:49.335638Z","iopub.status.idle":"2024-04-06T07:16:49.367781Z","shell.execute_reply.started":"2024-04-06T07:16:49.335611Z","shell.execute_reply":"2024-04-06T07:16:49.366933Z"}}},{"cell_type":"code","source":"idx2label=['sadness','joy','love','anger','fear','surprise']","metadata":{"execution":{"iopub.status.busy":"2024-04-06T07:18:17.883609Z","iopub.execute_input":"2024-04-06T07:18:17.884449Z","iopub.status.idle":"2024-04-06T07:18:17.888385Z","shell.execute_reply.started":"2024-04-06T07:18:17.884412Z","shell.execute_reply":"2024-04-06T07:18:17.887546Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"#### Preprocessing the dataset -\n* Each LLM expects data in a specific format\n* So here for TinyLlama converting the data to that specific format","metadata":{}},{"cell_type":"code","source":"PROMPT=\"Identify the sentiment in the given sentence.\"\ndef process_data_llm_format(sent):\n    sent['text']=f\"<|im_start|>user\\n{PROMPT} {sent['text']} <|im_end|>\\n<|im_start|>assistant\\n{idx2label[sent['label']]}<|im_end|>\"\n    return sent\n\ntrain_data=data['train'].map(process_data_llm_format,remove_columns=['label'])\nvalid_data=data['validation'].map(process_data_llm_format,remove_columns=['label'])\nprint(train_data[9]['text'])","metadata":{"execution":{"iopub.status.busy":"2024-04-06T07:24:58.683827Z","iopub.execute_input":"2024-04-06T07:24:58.684685Z","iopub.status.idle":"2024-04-06T07:24:59.799333Z","shell.execute_reply.started":"2024-04-06T07:24:58.684650Z","shell.execute_reply":"2024-04-06T07:24:59.798436Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/16000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2af44180975a45b3b8ad4b73fd295fd8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9353d0eef554046a45bc64fef8a1fb5"}},"metadata":{}},{"name":"stdout","text":"<|im_start|>user\nIdentify the sentiment in the given sentence. i feel romantic too <|im_end|>\n<|im_start|>assistant\nlove<|im_end|>\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Setting tokenizer,models,bitsandbytes,PEFT config","metadata":{}},{"cell_type":"code","source":"model_name=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\ntokenizer=AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token=tokenizer.eos_token\n# peft config\npeft_config=LoraConfig(r=8,lora_alpha=16,lora_dropout=0.05,bias=\"none\",task_type=\"CAUSAL_LM\")\n# bitsandbytes config\nbnb_config=BitsAndBytesConfig(load_in_4bit=True,\n                             bnb_4bit_quant_type=\"nf4\",\n                             bnb_4bit_compute_dtype=\"float16\",\n                             bnb_4bit_use_double_quant=True)\n# loading model using configurations\nmodel=AutoModelForCausalLM.from_pretrained(model_name,quantization_config=bnb_config,device_map=\"auto\")\nmodel.config.use_cache=False\nmodel.config.pretraining_tp=1\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-06T07:33:50.388630Z","iopub.execute_input":"2024-04-06T07:33:50.389012Z","iopub.status.idle":"2024-04-06T07:34:05.882081Z","shell.execute_reply.started":"2024-04-06T07:33:50.388983Z","shell.execute_reply":"2024-04-06T07:34:05.880958Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9842aba8e71f4cd69b204174ce58c5f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae281e0b91a545aabadd4aeed94553e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6740051435a404eb47c439aa3be18b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea7bc9bf12624790b582578698b39296"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78ea3a1352514ca19972c50ae27107b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b4782bc08c9440b9439913103c780ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0d6acc347c24bfdb8b03b713ed76015"}},"metadata":{}}]},{"cell_type":"markdown","source":"#### Setting up trainer using SFTTrainer and Peft config","metadata":{}},{"cell_type":"code","source":"training_arguments=TrainingArguments(output_dir=\"./logs\",\n                                    per_device_train_batch_size=16,gradient_accumulation_steps=4,\n                                    optim=\"paged_adamw_32bit\",learning_rate=2e-4,lr_scheduler_type=\"cosine\",\n                                    save_strategy=\"epoch\",logging_steps=250,max_steps=750,fp16=True)\ntrainer=SFTTrainer(model=model,train_dataset=train_data,eval_dataset=valid_data,peft_config=peft_config,\n                                    dataset_text_field=\"text\",args=training_arguments,\n                                    tokenizer=tokenizer,packing=False,max_seq_length=1024)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-06T07:39:51.517913Z","iopub.execute_input":"2024-04-06T07:39:51.518811Z","iopub.status.idle":"2024-04-06T07:39:53.410110Z","shell.execute_reply.started":"2024-04-06T07:39:51.518779Z","shell.execute_reply":"2024-04-06T07:39:53.409203Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/16000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a2c45a3de5e43bca2093149516322db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab4481c12eab40918c716646e289e727"}},"metadata":{}}]},{"cell_type":"code","source":"finetuned_model_id=\"./tinyllama-finetuned\"\ntrainer.train()\ntrainer.model.save_pretrained(finetuned_model_id)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T07:40:11.797216Z","iopub.execute_input":"2024-04-06T07:40:11.797591Z","iopub.status.idle":"2024-04-06T08:15:41.694724Z","shell.execute_reply.started":"2024-04-06T07:40:11.797564Z","shell.execute_reply":"2024-04-06T08:15:41.693750Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240406_074047-mckibo0t</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/akshat00000verma/huggingface/runs/mckibo0t' target=\"_blank\">crusher-spot-6</a></strong> to <a href='https://wandb.ai/akshat00000verma/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/akshat00000verma/huggingface' target=\"_blank\">https://wandb.ai/akshat00000verma/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/akshat00000verma/huggingface/runs/mckibo0t' target=\"_blank\">https://wandb.ai/akshat00000verma/huggingface/runs/mckibo0t</a>"},"metadata":{}},{"name":"stderr","text":"You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [750/750 34:17, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>250</td>\n      <td>1.237200</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.076200</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>1.067600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Merge the Lora with base model","metadata":{}},{"cell_type":"code","source":"pretrained_model=AutoModelForCausalLM.from_pretrained(model_name,torch_dtype=torch.float16,\n                                                     load_in_8bit=False,device_map=\"auto\",\n                                                     trust_remote_code=True)\npeft_model=PeftModel.from_pretrained(pretrained_model,finetuned_model_id,\n                                    from_transformers=True,device_map=\"auto\")\nmodel=peft_model.merge_and_unload()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T08:19:37.424718Z","iopub.execute_input":"2024-04-06T08:19:37.425017Z","iopub.status.idle":"2024-04-06T08:19:41.036377Z","shell.execute_reply.started":"2024-04-06T08:19:37.424991Z","shell.execute_reply":"2024-04-06T08:19:41.035160Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"#### Inferencing with this model-","metadata":{}},{"cell_type":"code","source":"generation_config = GenerationConfig(penalty_alpha=0.6,do_sample=True,top_k=5,temperature=0.5,repetition_penalty=1.2, \n    max_new_tokens=32,pad_token_id=tokenizer.eos_token_id)\ndef generate_response(prompt):\n    inputs=tokenizer(prompt,return_tensors=\"pt\").to('cuda')\n    outputs=model.generate(**inputs,generation_config=generation_config)\n    generated_response=tokenizer.decode(outputs[0],skip_special_tokens=True)\n    end_idx=generated_response.index('<|im_end|>',len(prompt))+len('<|im_end|>')\n    return generated_response[:end_idx]","metadata":{"execution":{"iopub.status.busy":"2024-04-06T08:21:16.289099Z","iopub.execute_input":"2024-04-06T08:21:16.289826Z","iopub.status.idle":"2024-04-06T08:21:16.297995Z","shell.execute_reply.started":"2024-04-06T08:21:16.289794Z","shell.execute_reply":"2024-04-06T08:21:16.296808Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def prepare_prompt_chatml_format(sample):\n    sample['prompt']=f\"<|im_start|>user\\n{PROMPT}{sample['text']}<|im_end|>\\n<|im_start|>assistant\\n\"\n    return sample\ntest_data=data['test'].map(prepare_prompt_chatml_format)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T08:22:18.585211Z","iopub.execute_input":"2024-04-06T08:22:18.585631Z","iopub.status.idle":"2024-04-06T08:22:18.735441Z","shell.execute_reply.started":"2024-04-06T08:22:18.585599Z","shell.execute_reply":"2024-04-06T08:22:18.734366Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e0dfd2bfd8d4797b818f9f00cb8dbed"}},"metadata":{}}]},{"cell_type":"code","source":"sample_prompt=test_data[0]['prompt']\nprint(generate_response(sample_prompt))","metadata":{"execution":{"iopub.status.busy":"2024-04-06T08:23:55.608380Z","iopub.execute_input":"2024-04-06T08:23:55.609250Z","iopub.status.idle":"2024-04-06T08:23:56.868895Z","shell.execute_reply.started":"2024-04-06T08:23:55.609216Z","shell.execute_reply":"2024-04-06T08:23:56.867856Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"<|im_start|>user\nIdentify the sentiment in the given sentence.im feeling rather rotten so im not very ambitious right now<|im_end|>\n<|im_start|>assistant\nsadness<|im_end|>\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}