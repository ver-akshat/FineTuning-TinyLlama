# FineTuning-TinyLlama
TinyLlama is a smaller variant of Llama-2 , it consists of 1.1 Billion parameters and is trained on 3 Trillion parameters.


In this notebook I am fine tuning this model on a custom dataset to predict sentiment of the text using PEFT technique.
